# Alungus AI - Multimodal AI Web App

A complete web-based application that includes AI-powered features for image, video, audio, 3D content generation, and intelligent chatbot interaction. Built with Next.js 15, TypeScript, and integrates with open-source AI models hosted locally or through Google Colab.

## üöÄ Features

### ü§ñ AI Generation Capabilities
- **Image Generation**: Stable Diffusion SDXL for text-to-image and image-to-image
- **Video Generation**: AnimateDiff for animation, ModelScope for realistic videos
- **Audio Generation**: Bark TTS for voice synthesis, MusicGen for music creation
- **3D Generation**: Threestudio for 3D characters, products, and objects
- **AI Chat**: Ollama integration with LLaMA 3, Mistral, and other LLMs

### üîê Authentication System
- **Multiple OAuth Providers**: Google, GitHub, X (Twitter), Microsoft Outlook
- **Email/Password Login**: Traditional authentication with MongoDB storage
- **Session Management**: JWT-based sessions with NextAuth.js

### üé® Modern UI/UX
- **Responsive Design**: TailwindCSS with mobile-first approach
- **Dark/Light Theme**: Theme switching with system preference detection
- **Component Library**: Radix UI + shadcn/ui for accessibility
- **Animations**: Framer Motion for smooth interactions

## üìÅ Project Structure

```
alungus-ai/
‚îú‚îÄ‚îÄ app/                    # Next.js 15 App Router
‚îÇ   ‚îú‚îÄ‚îÄ api/               # API endpoints
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ auth/          # NextAuth.js authentication
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ generate/      # AI generation endpoints
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ chat/          # Chat API
‚îÇ   ‚îú‚îÄ‚îÄ dashboard/         # Protected dashboard pages
‚îÇ   ‚îú‚îÄ‚îÄ auth/             # Authentication pages
‚îÇ   ‚îî‚îÄ‚îÄ globals.css       # Global styles
‚îú‚îÄ‚îÄ components/            # React components
‚îÇ   ‚îú‚îÄ‚îÄ ui/               # Base UI components (shadcn/ui)
‚îÇ   ‚îú‚îÄ‚îÄ generators/       # AI generation forms
‚îÇ   ‚îú‚îÄ‚îÄ chat/            # Chat interface
‚îÇ   ‚îú‚îÄ‚îÄ layout/          # Navigation, footer
‚îÇ   ‚îî‚îÄ‚îÄ sections/        # Landing page sections
‚îú‚îÄ‚îÄ lib/                  # Utility functions
‚îÇ   ‚îú‚îÄ‚îÄ auth.ts          # NextAuth configuration
‚îÇ   ‚îú‚îÄ‚îÄ utils.ts         # Utility functions
‚îÇ   ‚îî‚îÄ‚îÄ validations.ts   # Zod schemas
‚îú‚îÄ‚îÄ colab_notebooks/      # Google Colab notebooks
‚îú‚îÄ‚îÄ uploads/             # Local file storage
‚îú‚îÄ‚îÄ .env.local          # Environment variables
‚îî‚îÄ‚îÄ README.md
```

## üõ†Ô∏è Installation & Setup

### Prerequisites
- Node.js 18+ 
- MongoDB (local or Atlas)
- Git

### 1. Clone Repository
```bash
git clone https://github.com/your-username/alungus-ai.git
cd alungus-ai
```

### 2. Install Dependencies
```bash
npm install
```

### 3. Environment Setup
Copy `.env.local` and fill in your credentials:

```bash
# Database
MONGODB_URI=mongodb+srv://username:password@cluster.mongodb.net/alungus-ai

# NextAuth
NEXTAUTH_URL=http://localhost:3000
NEXTAUTH_SECRET=your-super-secret-jwt-key

# OAuth Providers
GOOGLE_CLIENT_ID=your-google-client-id
GOOGLE_CLIENT_SECRET=your-google-client-secret
GITHUB_CLIENT_ID=your-github-client-id
GITHUB_CLIENT_SECRET=your-github-client-secret

# AI Model Endpoints
COLAB_API_BASE_URL=https://your-colab-endpoint.ngrok.io
COLAB_API_TOKEN=your-colab-api-token
OLLAMA_ENDPOINT=http://localhost:11434
```

### 4. Run Development Server
```bash
npm run dev
```

Visit `http://localhost:3000` to see the application.

## üîß AI Model Setup

### Local Setup (Recommended for Development)

#### 1. Ollama (LLM Chat)
```bash
# Install Ollama
curl -fsSL https://ollama.com/install.sh | sh

# Download models
ollama pull llama3
ollama pull mistral
ollama pull phi3

# Start server (runs on localhost:11434)
ollama serve
```

#### 2. Stable Diffusion (Image Generation)
```bash
# Option A: AUTOMATIC1111 WebUI
git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui.git
cd stable-diffusion-webui
python launch.py

# Option B: ComfyUI (Alternative)
git clone https://github.com/comfyanonymous/ComfyUI.git
cd ComfyUI
pip install -r requirements.txt
python main.py
```

### Google Colab Setup (For Production/Fallback)

1. **Create Colab Notebooks** for each AI model type
2. **Install ngrok or cloudflared** for public endpoints
3. **Set up API endpoints** that match our `/api/generate/*` structure
4. **Configure authentication tokens** for security

#### Example Colab Setup:
```python
# In Google Colab
!pip install flask
!pip install diffusers transformers accelerate

from flask import Flask, request, jsonify
import torch
from diffusers import StableDiffusionPipeline

app = Flask(__name__)

# Load model
pipe = StableDiffusionPipeline.from_pretrained(
    "runwayml/stable-diffusion-v1-5",
    torch_dtype=torch.float16
).to("cuda")

@app.route('/api/sd/txt2img', methods=['POST'])
def generate_image():
    data = request.json
    image = pipe(data['prompt']).images[0]
    # Save and return image URL
    return jsonify({'image_url': 'https://...'})

# Expose via ngrok
!ngrok http 5000
```

## üåê Deployment

### Vercel Deployment
1. **Connect GitHub Repository** to Vercel
2. **Set Environment Variables** in Vercel dashboard
3. **Deploy** - automatic builds on push to main

### Environment Variables for Production:
```bash
NEXTAUTH_URL=https://your-app.vercel.app
NODE_ENV=production
# ... other variables same as development
```

## üîë OAuth Setup Guide

### Google OAuth
1. Go to [Google Cloud Console](https://console.cloud.google.com)
2. Create new project or select existing
3. Enable Google+ API
4. Create OAuth 2.0 credentials
5. Add authorized redirect URI: `https://your-app.vercel.app/api/auth/callback/google`

### GitHub OAuth
1. Go to GitHub Settings > Developer settings > OAuth Apps
2. Create new OAuth App
3. Set Authorization callback URL: `https://your-app.vercel.app/api/auth/callback/github`

### Microsoft OAuth
1. Go to [Azure Portal](https://portal.azure.com)
2. Register new application in Azure AD
3. Add redirect URI: `https://your-app.vercel.app/api/auth/callback/azure-ad`

## üì± Usage Examples

### Generate an Image
```javascript
const response = await fetch('/api/generate/image', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    prompt: "A cyberpunk cat wearing sunglasses",
    width: 1024,
    height: 1024,
    steps: 30
  })
})
```

### Chat with AI
```javascript
const response = await fetch('/api/chat', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    message: "Explain quantum computing",
    model: "llama3"
  })
})
```

## üöß Development Roadmap

- [ ] **v1.0**: Core AI generation features
- [ ] **v1.1**: Advanced model settings and LoRA support
- [ ] **v1.2**: Real-time generation progress tracking
- [ ] **v1.3**: User workspace and project management
- [ ] **v1.4**: API marketplace for custom models
- [ ] **v2.0**: Mobile app with React Native

## ü§ù Contributing

1. Fork the repository
2. Create feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## üìÑ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## üÜò Support & Issues

- **GitHub Issues**: For bug reports and feature requests
- **Discussions**: For general questions and community chat
- **Documentation**: Full API docs at `/docs` (coming soon)

## üôè Acknowledgments

- **Stability AI** for Stable Diffusion
- **Meta** for LLaMA and MusicGen
- **Suno AI** for Bark TTS
- **Threestudio** for 3D generation
- **Vercel** for hosting platform
- **MongoDB** for database services

---

**Built with ‚ù§Ô∏è by the Alungus AI Team**
